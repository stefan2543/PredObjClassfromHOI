{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a921edaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T09:56:28.343567Z",
     "start_time": "2023-06-08T09:56:22.228516Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import trimesh\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.spatial.transform import Rotation\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from popup.models.baseline_nn import create_nn_model, create_and_query_nn_model\n",
    "from popup.utils.exp import init_experiment\n",
    "from popup.core.evaluator import Evaluator\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d491b1fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T09:56:28.373530Z",
     "start_time": "2023-06-08T09:56:28.345082Z"
    }
   },
   "outputs": [],
   "source": [
    "arguments = SimpleNamespace(\n",
    "    scenario=Path(\"./scenarios/gb_nn_baseline.toml\"), \n",
    "    exp_name=\"nn_baseline\",\n",
    "    project_config=Path(\"./configs/smplh.toml\"),\n",
    "    experiment_prefix=\"nn_baseline\", resume_checkpoint=None, workers=None, \n",
    "    batch_size=None, lr=None, no_wandb=True\n",
    ")\n",
    "config = init_experiment(arguments, True)\n",
    "config.eval_temporal = False\n",
    "exp_folder = deepcopy(config.exp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a9d0aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T09:56:28.387236Z",
     "start_time": "2023-06-08T09:56:28.374766Z"
    }
   },
   "outputs": [],
   "source": [
    "objname2classid = config.objname2classid\n",
    "\n",
    "classid2objname = {v: k for k, v in objname2classid.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1b74ce",
   "metadata": {},
   "source": [
    "### NN Classsifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac7ceb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T08:49:27.830320Z",
     "start_time": "2023-06-08T08:45:09.327688Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kdtree, labels, test_queries, test_labels, test_t_stamps = \\\n",
    "    create_nn_model(config, \"classifier\", human_features=\"verts\", backend=\"faiss_gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19ae44d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T08:49:37.254166Z",
     "start_time": "2023-06-08T08:49:27.836579Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NEIGHBORS = 1\n",
    "\n",
    "dataset_to_pred_labels = {}\n",
    "for dataset in config.datasets:\n",
    "    _, pred_neighbors = kdtree.query(test_queries[dataset], k=NEIGHBORS)\n",
    "\n",
    "    for K in range(1, NEIGHBORS + 1):\n",
    "        _pred_labels = labels[pred_neighbors[:, :K]]\n",
    "        if K > 1:\n",
    "            pred_labels = np.zeros(len(_pred_labels), dtype=np.uint8)\n",
    "            for i, pred_label in enumerate(_pred_labels):\n",
    "                class_scores = np.bincount(pred_label)\n",
    "                pred_labels[i] = class_scores.argmax()\n",
    "        else:\n",
    "            pred_labels = _pred_labels.reshape(-1)\n",
    "\n",
    "        if K == 1:\n",
    "            dataset_to_pred_labels[dataset] = pred_labels\n",
    "\n",
    "        print(f\"{dataset} K={K} | ACC: {100 * np.mean(test_labels[dataset] == pred_labels):02f}\")\n",
    "    \n",
    "# PER CLASS PREDICTIONS\n",
    "for class_id in range(len(classid2objname)):\n",
    "    all_pred, all_gt = [], []\n",
    "    for dataset in config.datasets:\n",
    "        mask = test_labels[dataset] == class_id\n",
    "        \n",
    "        all_pred.append(dataset_to_pred_labels[dataset][mask])\n",
    "        all_gt.append(test_labels[dataset][mask])\n",
    "    \n",
    "    all_pred = np.concatenate(all_pred, axis=0)\n",
    "    all_gt = np.concatenate(all_gt, axis=0)\n",
    "    \n",
    "    print(f\"{classid2objname[class_id]:20s} ACC {100 * np.mean(all_pred == all_gt):02f}\")\n",
    "\n",
    "# CONFUSION MATRIX\n",
    "font = {'weight': 'bold', 'size': 15}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "all_pred, all_gt = [], []\n",
    "for dataset in config.datasets: \n",
    "    all_pred.append(dataset_to_pred_labels[dataset])\n",
    "    all_gt.append(test_labels[dataset])\n",
    "all_pred = np.concatenate(all_pred, axis=0)\n",
    "all_gt = np.concatenate(all_gt, axis=0)\n",
    "\n",
    "cmtrx = confusion_matrix(all_gt, all_pred)\n",
    "fig = plt.figure(figsize=(30, 30))\n",
    "axes_labels = [classid2objname[class_id] for class_id in sorted(classid2objname.keys())]\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    all_gt, all_pred, xticks_rotation=\"vertical\", display_labels=axes_labels, ax=plt.gca()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe64e34d",
   "metadata": {},
   "source": [
    "### NN pose general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27984e8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T08:55:13.999544Z",
     "start_time": "2023-06-08T08:49:37.255305Z"
    }
   },
   "outputs": [],
   "source": [
    "kdtree, labels, test_queries, test_labels, test_t_stamps = \\\n",
    "    create_nn_model(config, \"pose_general\",  human_features=\"verts\", backend=\"faiss_gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec17aef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T08:55:14.021263Z",
     "start_time": "2023-06-08T08:55:14.004212Z"
    }
   },
   "outputs": [],
   "source": [
    "canonical_meshes_path = dict()\n",
    "for dataset in config.datasets:\n",
    "    if dataset == \"grab\":\n",
    "        dataset_path = config.grab_path\n",
    "    elif dataset == \"behave\":\n",
    "        dataset_path = config.behave_path\n",
    "    \n",
    "    dataset_objects = list((dataset_path / \"object_keypoints\").glob(\"*.npz\"))\n",
    "    dataset_objects = [object_name.stem for object_name in dataset_objects]\n",
    "\n",
    "    for class_id, object_name in classid2objname.items():\n",
    "        if object_name in dataset_objects:\n",
    "            canonical_meshes_path[class_id] = str(dataset_path / \"object_meshes\" / f\"{object_name}.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0516d800",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T08:56:54.009940Z",
     "start_time": "2023-06-08T08:55:14.022010Z"
    }
   },
   "outputs": [],
   "source": [
    "NEIGHBORS = 1\n",
    "\n",
    "dataset_to_pred_labels = {}\n",
    "for dataset in config.datasets:\n",
    "    if dataset == \"grab\":\n",
    "        dataset_path = config.grab_path\n",
    "    elif dataset == \"behave\":\n",
    "        dataset_path = config.behave_path\n",
    "        \n",
    "    _, pred_neighbors = kdtree.query(test_queries[dataset], k=NEIGHBORS)\n",
    "    dataset_to_pred_labels[dataset] = {}\n",
    "    for K in range(1, NEIGHBORS + 1):\n",
    "        target_dir = exp_folder / \"pose_general\" / f\"{K}/visualization/0/{dataset}\"\n",
    "        _pred_labels = labels[pred_neighbors[:, :K]]\n",
    "        \n",
    "        dataset_to_pred_labels[dataset][K] = []\n",
    "        for sample_id in tqdm(range(len(_pred_labels))):            \n",
    "            sample_t_stamp = dataset_path / str(test_t_stamps[dataset][sample_id])\n",
    "\n",
    "            # prediction is flattened 3x3 pca_axes and center location\n",
    "            _pred_label = _pred_labels[sample_id]\n",
    "\n",
    "            pred_class = _pred_label[:, 0]\n",
    "            if K > 1:\n",
    "                class_scores = np.bincount(pred_class.astype(np.int8))\n",
    "                pred_class = class_scores.argmax()\n",
    "            else:\n",
    "                pred_class = pred_class[0].astype(np.int8)\n",
    "            dataset_to_pred_labels[dataset][K].append(pred_class)\n",
    "            pred_rot = _pred_label[:, 1:10].mean(axis=0).reshape(3, 3)\n",
    "            pred_center = _pred_label[:, 10:].mean(axis=0)\n",
    "\n",
    "            # load mesh\n",
    "            predicted_mesh = trimesh.load(canonical_meshes_path[pred_class], process=False)\n",
    "\n",
    "            # load preprocessing params\n",
    "            with (sample_t_stamp / \"preprocess_transform.pkl\").open(\"rb\") as fp:\n",
    "                preprocess_transform = pkl.load(fp)\n",
    "            preprocess_params = (\n",
    "                np.array(preprocess_transform[\"translation\"], dtype=np.float32), \n",
    "                preprocess_transform[\"scale\"]\n",
    "            )\n",
    "            scale = preprocess_params[1]\n",
    "\n",
    "            # construct rotation\n",
    "            R = Rotation.from_matrix(pred_rot.reshape(3, 3))\n",
    "\n",
    "            # save the resulting mesh\n",
    "            sbj, obj_act, t_stamp = str(test_t_stamps[dataset][sample_id]).split(\"/\")\n",
    "            posed_mesh_path = target_dir / sbj / obj_act / \"posed_mesh\" / f\"{t_stamp}.obj\"\n",
    "            posed_mesh_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            predicted_mesh.vertices = R.apply(scale * predicted_mesh.vertices) + pred_center\n",
    "            _ = predicted_mesh.export(str(posed_mesh_path))\n",
    "        dataset_to_pred_labels[dataset][K] = np.array(dataset_to_pred_labels[dataset][K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed26899",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T09:08:24.899657Z",
     "start_time": "2023-06-08T08:56:54.010842Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# _exp_folder = config.exp_folder\n",
    "config.grab[\"gen_subjects\"] = [\"s9\", \"s10\"]\n",
    "config.grab[\"gen_objects\"] = config.grab[\"val_objects\"]\n",
    "config.grab[\"gen_actions\"] = config.grab[\"val_actions\"]\n",
    "config.behave[\"gen_objects\"] = config.behave[\"val_objects\"]\n",
    "config.behave[\"gen_split_file\"] = config.behave[\"val_split_file\"]\n",
    "config.undo_preprocessing_eval = True\n",
    "\n",
    "for dataset in config.datasets:\n",
    "    gt_classes = test_labels[dataset][:, 0].astype(np.int32) \n",
    "    for K in range(1, NEIGHBORS + 1):\n",
    "        pred = dataset_to_pred_labels[dataset][K]\n",
    "\n",
    "        print(f\"{dataset} K={K} | ACC: {100 * np.mean(gt_classes == pred):02f}\")\n",
    "\n",
    "for K in range(1, NEIGHBORS + 1):\n",
    "    print(40*\"=\")\n",
    "    print(f\"K={K}\")\n",
    "    print(40*\"=\")\n",
    "    config.exp_folder = exp_folder / \"pose_general\" / f\"{K}\"\n",
    "    evaluator = Evaluator(torch.device(\"cuda:0\"), config)\n",
    "    evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa96747",
   "metadata": {},
   "source": [
    "### NN pose class-specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6604d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:00:49.152880Z",
     "start_time": "2023-06-08T09:56:28.388516Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_neighbors, train_labels, test_labels, test_t_stamps = create_and_query_nn_model(\n",
    "    config, \"pose_class_specific\",  human_features=\"verts\", n_neighbors=3, backend=\"faiss_gpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec98d6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:00:49.178844Z",
     "start_time": "2023-06-08T10:00:49.154201Z"
    }
   },
   "outputs": [],
   "source": [
    "canonical_meshes_path = dict()\n",
    "for dataset in config.datasets:\n",
    "    if dataset == \"grab\":\n",
    "        dataset_path = config.grab_path\n",
    "    elif dataset == \"behave\":\n",
    "        dataset_path = config.behave_path\n",
    "    \n",
    "    dataset_objects = list((dataset_path / \"object_keypoints\").glob(\"*.npz\"))\n",
    "    dataset_objects = [object_name.stem for object_name in dataset_objects]\n",
    "\n",
    "    for class_id, object_name in classid2objname.items():\n",
    "        if object_name in dataset_objects:\n",
    "            canonical_meshes_path[class_id] = str(dataset_path / \"object_meshes\" / f\"{object_name}.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674f6c0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:02:33.587584Z",
     "start_time": "2023-06-08T10:00:49.180314Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "NEIGHBORS = 1\n",
    "\n",
    "for K in range(1, NEIGHBORS + 1):\n",
    "    for class_id in tqdm(classid2objname.keys()):\n",
    "        for dataset in config.datasets:\n",
    "            if dataset == \"grab\":\n",
    "                dataset_path = config.grab_path\n",
    "            elif dataset == \"behave\":\n",
    "                dataset_path = config.behave_path\n",
    "            target_dir = exp_folder / \"pose_class_specific\" / f\"{K}/visualization/0/{dataset}\"    \n",
    "\n",
    "            if not dataset in pred_neighbors[class_id]:\n",
    "                continue\n",
    "\n",
    "            _pred_labels = train_labels[class_id][pred_neighbors[class_id][dataset][:, :K]]\n",
    "            _test_t_stamps = test_t_stamps[dataset][class_id]\n",
    "\n",
    "\n",
    "            for sample_id in tqdm(range(len(_pred_labels)), leave=False):\n",
    "                _pred_label = np.mean(_pred_labels[sample_id], axis=0)\n",
    "                sample_t_stamp = dataset_path / str(_test_t_stamps[sample_id])\n",
    "\n",
    "                # prediction is flattened 3x3 pca_axes and center location\n",
    "                pred_rot = _pred_label[:9].reshape(3, 3)\n",
    "                pred_center = _pred_label[9:]\n",
    "\n",
    "                # load gt_mesh\n",
    "                class_name = _test_t_stamps[sample_id].split(\"/\")[1].split(\"_\")[0]\n",
    "                predicted_mesh = trimesh.load(canonical_meshes_path[objname2classid[class_name]], process=False)\n",
    "\n",
    "                # load preprocessing params\n",
    "                with (sample_t_stamp / \"preprocess_transform.pkl\").open(\"rb\") as fp:\n",
    "                    preprocess_transform = pkl.load(fp)\n",
    "                preprocess_params = (\n",
    "                    np.array(preprocess_transform[\"translation\"], dtype=np.float32), \n",
    "                    preprocess_transform[\"scale\"]\n",
    "                )\n",
    "                scale = preprocess_params[1]\n",
    "\n",
    "                # construct rotation\n",
    "                R = Rotation.from_matrix(pred_rot)\n",
    "\n",
    "                # save the resulting mesh\n",
    "                sbj, obj_act, t_stamp = str(_test_t_stamps[sample_id]).split(\"/\")\n",
    "                posed_mesh_path = target_dir / sbj / obj_act / \"posed_mesh\" / f\"{t_stamp}.obj\"\n",
    "                posed_mesh_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                predicted_mesh.vertices = R.apply(scale * predicted_mesh.vertices) + pred_center\n",
    "                _ = predicted_mesh.export(str(posed_mesh_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dafba2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:12:38.452122Z",
     "start_time": "2023-06-08T10:02:33.588829Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _exp_folder = config.exp_folder\n",
    "config.grab[\"gen_subjects\"] = [\"s9\", \"s10\"]\n",
    "config.grab[\"gen_objects\"] = config.grab[\"val_objects\"]\n",
    "config.grab[\"gen_actions\"] = config.grab[\"val_actions\"]\n",
    "config.behave[\"gen_objects\"] = config.behave[\"val_objects\"]\n",
    "config.behave[\"gen_split_file\"] = config.behave[\"val_split_file\"]\n",
    "config.undo_preprocessing_eval = True\n",
    "\n",
    "for K in range(1, NEIGHBORS + 1):\n",
    "    print(40*\"=\")\n",
    "    print(f\"K={K}\")\n",
    "    print(40*\"=\")\n",
    "    config.exp_folder = exp_folder / \"pose_class_specific\" / f\"{K}\"\n",
    "    evaluator = Evaluator(torch.device(\"cuda:0\"), config)\n",
    "    evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ac6461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "popup",
   "language": "python",
   "name": "popup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
